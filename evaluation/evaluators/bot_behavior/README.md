# Bot Behavior Evaluator

## Overview

The **Bot Behavior Evaluator** is a tool designed to assess the alignment of a bot's responses with predefined expected behaviors. This evaluation process ensures that the bot adheres to guidelines and maintains a high standard of interaction quality.

## Purpose

The primary purpose of this evaluator is to provide a systematic way to score the responses generated by a bot. By quantifying the alignment of answers with expected behaviors, developers and researchers can make informed decisions about refining the bot's performance and improving user interactions.

## Inputs

The evaluator requires the following inputs:

- **question** (`string`): The question posed to the bot. This input represents the context or prompt that the bot is responding to.

- **answer** (`string`): The response generated by the bot. This is the actual output that needs to be evaluated against the expected behavior.

- **expected_behavior** (`string`): A description of the guidelines and standards that the bot is expected to follow when formulating its response. This sets the benchmark for the evaluation.

## Outputs

The evaluator produces two main outputs:

- **score** (`int`): An integer score ranging from 1 to 5 that reflects how well the bot's answer aligns with the expected behavior. The scoring criteria are as follows:
  - **1**: No alignment with expected behavior.
  - **2**: Minimal alignment with expected behavior.
  - **3**: Partial alignment with expected behavior.
  - **4**: Mostly aligns with expected behavior.
  - **5**: Perfect alignment with expected behavior.

- **reason** (`string`): A detailed explanation of the score assigned. This reason should clarify the rationale behind the scoring, highlighting specific areas of alignment or misalignment with the expected behavior.

## Evaluation Process

1. **Input Collection**: The evaluator collects the question, the bot's answer, and the expected behavior.

2. **Scoring**: The evaluator analyzes the answer in the context of the expected behavior and assigns a score based on the scoring criteria.

3. **Reasoning**: A detailed reason is generated to explain why the score was given, providing insights into the evaluation process.

## Example Output

The response from the evaluator is structured in JSON format, which allows for easy integration with other systems. An example output might look like this:

```json
{
    "score": 4,
    "reason": "The answer mostly aligns with the expected behavior, addressing the question correctly and providing relevant information, although it could have included more detail."
}
